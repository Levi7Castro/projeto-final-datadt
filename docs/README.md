# ğŸš€ Projeto Final: Da OperaÃ§Ã£o ao Preditivo â€“ Vendas e FinanÃ§as

## ğŸ¯ 1. VisÃ£o Geral e Contexto de NegÃ³cio

[cite_start]Este projeto de Engenharia de Dados e Machine Learning visa modernizar a tomada de decisÃ£o de uma empresa de varejo, que busca evoluir de relatÃ³rios operacionais para uma gestÃ£o baseada em dados[cite: 3].

[cite_start]A soluÃ§Ã£o transforma dados transacionais de **Vendas**, **Contas a Receber** e **Contas a Pagar** [cite: 5, 6, 7] [cite_start]em insights preditivos e acionÃ¡veis, focando em otimizar as Ã¡reas de marketing e cobranÃ§a[cite: 15].

### [cite_start]ğŸ”‘ Objetivos do Projeto [cite: 17]

* [cite_start]**Pipeline ETL:** Construir um pipeline ETL em Python (extraÃ§Ã£o â†’ transformaÃ§Ã£o â†’ qualidade â†’ carga)[cite: 18].
* [cite_start]**Data Warehouse (DW):** Modelar um DW em esquema estrela no SQL Server, integrando as Ã¡reas Vendas e Financeiro[cite: 14, 19].
* [cite_start]**Data Lake:** Publicar um *slice* analÃ­tico particionado em formato Parquet no Hadoop (HDFS)[cite: 20].
* [cite_start]**Machine Learning (ML):** Treinar e avaliar modelos preditivos a partir do Data Lake para problemÃ¡ticas de negÃ³cio, como **Recompra em 90 dias** (ClassificaÃ§Ã£o) ou **Atraso no Pagamento** (ClassificaÃ§Ã£o)[cite: 21, 22, 23].

## ğŸ§± 2. Arquitetura da SoluÃ§Ã£o

O projeto segue um fluxo de dados completo, desde a origem transacional atÃ© o consumo analÃ­tico e preditivo. 

### [cite_start]2.1 Tecnologias Utilizadas [cite: 27, 28, 29, 30]

| Camada | Ferramenta/Requisito | Detalhe |
| :--- | :--- | :--- |
| **Origem** | PostgreSQL | Base de dados transacional. |
| **OrquestraÃ§Ã£o** | Apache Airflow | [cite_start]Agendamento e automaÃ§Ã£o reprodutÃ­vel[cite: 16]. |
| **ETL & Data Lake** | Python (Pandas, pyodbc/SQLAlchemy, pyarrow) | Linguagem de processamento e bibliotecas de dados. |
| **Data Warehouse** | SQL Server | [cite_start]Banco de dados analÃ­tico (instÃ¢ncia local ou remota)[cite: 14, 28]. |
| **Data Lake** | Hadoop/HDFS (Parquet) | [cite_start]Armazenamento de *slice* particionado pronto para ML[cite: 29]. |
| **Machine Learning** | scikit-learn, LightGBM/XGBoost | Treinamento e avaliaÃ§Ã£o de modelos preditivos. |
| **Versionamento** | Git | [cite_start]Controle de cÃ³digo-fonte[cite: 31]. |

### 2.2 Estrutura do RepositÃ³rio

projeto-final-datadt/ â”œâ”€â”€ airflow/ # Scripts e DAGs para orquestraÃ§Ã£o (Agendamento no Aiflow ) â”‚ â”œâ”€â”€ dags/ â”‚ â””â”€â”€ requirements.txt â”œâ”€â”€ etl/ # Scripts Python de ExtraÃ§Ã£o, TransformaÃ§Ã£o e Carga (ETL Python ) â”œâ”€â”€ dw/ # Scripts SQL de DDL e DML para o SQL Server (Data Warehouse ) â”œâ”€â”€ lake/ # Scripts para gerar o Slice Parquet no HDFS (Data Lake ) â”œâ”€â”€ ml/ # Notebooks de modelagem (Notebook de modelagem ) e scoring â”œâ”€â”€ docs/ # Arquitetura & DocumentaÃ§Ã£o (Diagrama do fluxo ) â”œâ”€â”€ reports/ # Painel/RelatÃ³rio final com KPIs e Plano de aÃ§Ã£o  â”œâ”€â”€ .env # VariÃ¡veis de ambiente (IGNORADO) â””â”€â”€ README.md

## ğŸ› ï¸ 3. ConfiguraÃ§Ã£o e ExecuÃ§Ã£o

### 3.1 Credenciais da Fonte de Dados

As credenciais para acesso ao PostgreSQL transacional sÃ£o:

* **Host:** `postgresql-datadt.alwaysdata.net` [cite: 9]
* **Database:** `datadt_digital_corporativo` [cite: 10]
* **User:** `datadt_data_analytics` [cite: 11]
* **Password:** `DataAnalytics$100` [cite: 12]

***REGRAS DE OURO:** Estas credenciais devem ser armazenadas em um arquivo `.env` para evitar exposiÃ§Ã£o e garantir a privacidade[cite: 58].*

### 3.2 Setup do Ambiente

1.  **Clone o RepositÃ³rio:**
    ```bash
    git clone [link-do-seu-repositorio]
    cd projeto-final-datadt
    ```

2.  **Crie e Ative o Ambiente Virtual:**
    ```bash
    python -m venv .venv
    # Windows
    .\.venv\Scripts\activate
    # Linux/macOS
    source ./.venv/bin/activate
    ```

3.  **Instale as DependÃªncias:**
    ```bash
    pip install -r airflow/requirements.txt
    ```

### 3.3 Ordem de ExecuÃ§Ã£o do Pipeline (ReprodutÃ­vel) [cite: 56]

Para garantir a reprodutibilidade ("do zero ao fim"), o pipeline deve ser executado na seguinte ordem (ou orquestrado pelo Airflow):

1.  **CriaÃ§Ã£o do DW:** Executar os scripts DDL em `dw/` no SQL Server.
2.  **Carga ETL:** Rodar o script principal em `etl/` para carga no SQL Server (Staging â†’ DW)[cite: 39].
3.  **ExportaÃ§Ã£o para o Lake:** Rodar o script em `lake/` para gerar o Parquet particionado no HDFS[cite: 40].
4.  **Modelagem ML:** Executar o notebook/script em `ml/` para Treinar e Avaliar o modelo[cite: 44, 45].

## ğŸ“ˆ 4. CritÃ©rios de AvaliaÃ§Ã£o (EntregÃ¡veis Principais)

| EntregÃ¡vel | Detalhes | MÃ©tricas/Qualidade |
| :--- | :--- | :--- |
| **Modelagem DW** | Modelo de Dados e scripts SQL (DDL/DML) em `dw/`[cite: 37]. |
| **Carga ETL** | Scripts Python funcionais e reprodutÃ­veis em `etl/`[cite: 38, 56]. |
| **Data Lake** | Slice Parquet em `hdfs/` com particionamento Ãºtil (ex.: ano/mÃªs)[cite: 43]. |
| **Modelo Preditivo** | Notebook/Script de modelagem em `ml/`. | ClassificaÃ§Ã£o: **AUC**, **PR-AUC**, **Recall@k (k=10%)**[cite: 46]. RegressÃ£o: **MAE** e **sMAPE**[cite: 47]. |
| **ExportaÃ§Ã£o ML** | ExportaÃ§Ã£o do modelo treinado (`.joblib`) e pipeline de *scoring*[cite: 48]. |
| **DocumentaÃ§Ã£o** | Diagrama de arquitetura em `docs/` e documentaÃ§Ã£o de "assunÃ§Ãµes"[cite: 34, 55]. |
| **RelatÃ³rio Final** | KPIs, distribuiÃ§Ã£o de scores e **Plano de aÃ§Ã£o**[cite: 51, 52]. |